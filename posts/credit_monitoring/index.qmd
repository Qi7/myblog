---
title: "Monitoring a Credit Business"
author: "Qi Wang"
date: 2024-11-10
categories: ["credit risk", "monitoring"]
format: 
  html:
    mermaid:
      theme: default
execute: 
  echo: false
  warning: false
  error: false
  cache: false
  freeze: auto
toc: true
toc-depth: 3
number-sections: true
---


## Data Generating Process

The first step in analyzing data from any specific domain is understanding the data-generating process. This is why having domain knowledge or consulting subject matter experts is crucial. Lending and borrowing are common activities in both everyday life and the business world. To provide a clearer understanding of the data we will be working with, I created a diagram to illustrate a simplified data-generating process, as shown in @fig-DGP.

![Simplified Data Genrating Process](DGP.svg){width=80% .lightbox .border #fig-DGP}

During the application process, applicants’ features—such as demographic characteristics, socioeconomic factors, and other relevant data—are analyzed to assess their creditworthiness. Applicants who do not meet the criteria are rejected. For those who are approved, a credit line and an interest rate are assigned based on their evaluation. Once clients are granted credit, they can utilize it in accordance with the agreement established between the bank and themselves. Typically, we track and record two key actions: borrowing and repayment.

For rejected applicants, their potential behavior had they been granted credit remains unknown. These individuals are only included in data analyses related to the application process, such as calculating rejection rates under the current approval strategy and examining the distribution of the reasons that triggered their rejection.


## Monitor the Application Process

The rejection process typically involves multiple steps. An applicant may pass through several decision engines during evaluation. In this example, I simulated data to represent a process where applications first go through an anti-fraud engine. Only if they pass this initial step are they then evaluated by a strategy engine. This approach minimizes the need to retrieve downstream data for rejected applicants, thereby reducing the cost of acquiring additional data (because yes, data is not free).

```{r passrate}
library(tidyverse)
library(plotly)
library(lubridate)

# to set color scales
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

# Generate a sequence of year months
start_date <- ym("2023-01")
end_date <- ym("2023-12")
months <- seq.Date(start_date, end_date, by = "1 month")

# Format the sequence as year-month
formatted_months <- format(months, "%Y-%m")

result <- as.factor(c("reject-antifraud", "reject-strategy", "pass"))

generate_probabilities <- function() {
    # Generate random probabilities for a, b, and c
    prob_a <- runif(1)
    prob_b <- runif(1)
    prob_c <- runif(1)

    # Normalize the probabilities to ensure they add up to 1
    total_prob <- prob_a + prob_b + prob_c
    prob_a <- prob_a / total_prob
    prob_b <- prob_b / total_prob
    prob_c <- prob_c / total_prob

    return(sort(c(prob_a, prob_b, prob_c)))
}

# Function to generate a dataframe for each item in the vector
generate_dataframe <- function(item) {
    data_frame <- data.frame(
        month = item,
        result = sample(result, size = sample(10000:50000, 1), replace = TRUE, prob = generate_probabilities())
    )
    return(data_frame)
}

fig <- formatted_months %>%
    map_df(generate_dataframe) %>%
    bind_rows()

fig <- as_tibble(fig)

fig <- fig %>%
    mutate(reject_reasons = map(result, ~ sample(letters[1:20],
        size = sample(1:7, 1),
        prob = c(log(2:11), log(15:6))
    )))

fig <- fig %>% mutate(reject_reasons = ifelse(result == "通过", list(), reject_reasons))
# fig <- ggplot2::diamonds

t_reject_reasons <- fig %>% filter(result != "通过")

fig <- plot_ly(
    x = fig$month,
    color = fig$result,
    type = "histogram", 
    histfunc = "sum",
    colors = "viridis"
) %>%
    layout(
      barmode = "stack"
      , barnorm = "percent"
      , legend = list(orientation = 'h')
      )

fig
```

When we observe significant fluctuations in the pass rate, it’s essential to zoom in and analyze the rejection reasons for each specific period.

```{r reject_reasons}
t_reject_reason_count <- t_reject_reasons %>%
    unnest(reject_reasons) %>%
    group_by(month, reject_reasons) %>%
    summarise(n = n())
unique_months <- unique(t_reject_reason_count$month)
max_n <- t_reject_reason_count$n %>% max()
ojs_define(reject_reason = t_reject_reason_count)
ojs_define(unique_months = unique_months)
ojs_define(max_n = max_n)
```

### Monitor the Reject Reasons

```{ojs}
//| echo: false
//| panel: input
viewof select_month = Inputs.select(unique_months, {label: "Select the Month"})
```


::: {.panel-tabset}

#### Visualization

```{ojs}
Plot.plot({
  y: {domain: [0, max_n], 
  label: "trigger times"},
  x: {label: "trigger reasons"},

marks: [
Plot.barY(filtered_data, {x: "reject_reasons", y: "n", fill: "reject_reasons", sort: {x: "y", limit:10, reverse: true}})]
})
```

#### Data
```{ojs}
Inputs.table(filtered_data)
```

:::

```{ojs}
//| echo: false
filtered_data = transpose(reject_reason).filter((d) => d.month === select_month)
```

### Model Score Distribution

Another way to assess the quality of incoming clients is by examining the distribution of model scores or key features. In essence, all creditworthiness scores are methods of reducing the dimensionality of a client’s features, condensing them into a single scalar value. This allows us to compare clients by simply ranking their scores. Assuming the model is effective, monitoring these scores can provide an early warning of significant shifts in the creditworthiness of our client base.


```{r violin_plot}
library(plotly)
library(tidyverse)
library(ggplot2)
library(showtext)
showtext_auto()

# simulate some client data to visualize
balance_age <- 0:19

generate_cohorts <- function(start = "2021-01", end = "2021-12") {
    # Generate a sequence of year months
    start_date <- ym(start)
    end_date <- ym(end)
    months <- seq.Date(start_date, end_date, by = "1 month")

    # Format the sequence as year-month
    cohorts <- format(months, "%Y-%m")
    return(cohorts)
}

cohorts <- generate_cohorts()

# simulate scores for each month
df_score <- cohorts %>%
    map(~ tibble(
        month = .x,
        score = pmax(500, rnorm(1000, mean = sample(600:700, 1), sd = 50))
    )) %>%
    bind_rows()
p_boxplot <- ggplot(data = df_score) +
    geom_boxplot(aes(x = month, y = score, fill = month)) +
    theme_minimal()

ggplotly(p_boxplot)
```

## Monitor Client Behaviour Data

The primary metrics used to evaluate the health of a credit business include indicators such as vintage analysis, rolling rates, and others. However, an important initial question to consider is: do all clients with a credit line actually utilize their credit to borrow?

### When to Use the Credit

Credit is extended to clients based on their assessed creditworthiness. However, not all clients will utilize their available credit. Monitoring the credit utilization rate is crucial for evaluating the overall health of the business.

```{r}
data_credit_uti <- cohorts %>%
    map(~ tibble(
        cohort = .x,
        applied_clients = rnorm(1, 100000, 10000),
        utilize_prop = min(rnorm(1, 0.6, 0.1), 1),
        utilize_client = round(utilize_prop * applied_clients)
    )) %>%
    bind_rows()

fig <- plot_ly() %>%
    add_trace(
        data = data_credit_uti
        , x = ~cohort
        , y = ~applied_clients
        , type = "bar"
        , name = "# Clients"
        , hovertemplate = "Approval Month：%{x}<br># Clients: %{y}<extra></extra>"
        , marker = list(color = "#443983")
    )

ay <- list(
    overlaying = "y",
    side = "right",
    title = "credit utilization rate"
)

fig <- fig %>% add_trace(
    data = data_credit_uti, x = ~cohort, y = ~utilize_prop,
    name = "credit utilization rate", yaxis = "y2", mode = "lines+markers",
    type = "scatter",
    hovertemplate = "Approval Month：%{x}<br>util. rate: %{y:.0%}<extra></extra>"
)

fig <- fig %>%
    layout(
        title = "",
        yaxis2 = ay,
        xaxis = list(title = ""),
        yaxis = list(title = "Approved Number of Clients")
    ) %>%
    layout(
        xaxis = list(
            zerolinecolor = "#ffff",
            zerolinewidth = 2,
            gridcolor = "ffff"
        ),
        yaxis = list(
            zerolinecolor = "#ffff",
            zerolinewidth = 2,
            gridcolor = "ffff"
        )
    )

fig
```

How long does it take for a client to start using their credit after approval? To get a general sense, we can examine the distribution of credit usage. This can be further refined by splitting the data into more detailed groups, such as by approval month.

```{r}
time_to_use <- rchisq(sample(10000:50000, 1), 40) %>% round()

plot_ly(x = time_to_use, type = "histogram", marker = list(color = "#443983"))
```

### How is the Default Situation

The primary risk in the credit business is default. If we do not account for the time value of money, the final profit can be significantly impacted by the probability of default (PD).

$$profit = principal \cdot [(1-PD) \cdot i\% - c\% - PD \cdot (1 - r\%)]$$

#### Vintage Analysis

It’s essential to closely monitor default risks to prevent avoidable losses. One common method for assessing this risk is vintage analysis, a concept borrowed from enology. Loans issued during different periods or under different strategies can show varying default rates over time. Generally, the default rate increases initially, then flattens out as the loans mature, until all loans are eventually settled.

```{r tanh}
gen_vintage_data <- function(cohort_name){
  age <- seq(0, 100)
  vintage <- tanh(age/10)*runif(1, 0.01, 0.07)

  df = data.frame(cohort = cohort_name, age = age, default_rate = vintage)
  return(df)
}

df <- purrr::map_df(sample(letters, 3), gen_vintage_data) %>% rbind()

vintage_plot <- ggplot(data=df) +
  geom_line(aes(x=age, y=default_rate, col=cohort)) + 
  theme_minimal()

ggplotly(vintage_plot)
```

#### Rolling Rate

While vintage analysis tracks the progression of a cohort over time, the rolling rate measures how accounts transition between different states within a fixed period. For example, we can assess the proportion of accounts that have reached state M1 (1 to 29 days overdue) and how many of them will deteriorate to state M2 (30 to 59 days overdue) after 30 days. From observations, the longer a client remains in default, the less likely they are to repay the debt. As a result, rolling rates typically increase as the severity of the default status worsens.

```{r migration_rate}
n <- length(cohorts)
df_mig <- tibble(cohort = cohorts
      , c_m1 = pmax(0, rnorm(n, 0.05, 0.02))
       , m1_m2 = pmax(0, rnorm(n, 0.3, 0.05))
       , m2_m3 = pmax(0, rnorm(n, 0.8, 0.1))
       , m3_m4 = pmax(0, rnorm(n, 0.9, 0.05))
       , m4_m5 = pmax(0, rnorm(n, 0.95, 0.05))
       , m5_m6 = pmax(0, rnorm(n, 0.99, 0.03))
       )

df_mig_long <- df_mig %>% pivot_longer(cols = -1, names_to = 'migrate_status', values_to = 'value') 
ojs_define(df_mig = df_mig_long)
```

```{ojs}
// this plot is ugly, refine it later
Plot.plot({
  color: {
    legend: true, 
    type: "sequential",
    scheme: "Viridis"
    }, 
  y: {label: null},
  x: {label: null},
  marks: [
    Plot.cell(transpose(df_mig), {
      x: 'cohort',
      y: 'migrate_status',
      fill: 'value',
      tip: true 
    })
  ]
})
```

## Monitor the Effectiveness of the Model Scores

In the credit evaluation process, various scores—such as application scores and behavior scores—are used to assess clients’ creditworthiness during both the application and usage phases. During model development, performance is typically evaluated using metrics like accuracy, ROC AUC, and KS. However, post-deployment, it’s crucial to monitor how well these scores generalize to unseen, real-world clients. As mentioned earlier, new clients require time to interact with the business and demonstrate their creditworthiness through borrowing and repayment behaviors. In the meantime, we can begin by analyzing score distributions to identify any emerging patterns or anomalies.

### Score Stability

Once a model is deployed, it’s essential to ensure that the data used for serving remains consistent with the data used during training. This is critical for addressing the training-serving skew issue in MLOps. A useful way to monitor this consistency is by analyzing the distribution of scores for new applicants. If significant drift is detected in client profiles, it should serve as a warning sign, prompting a review to assess whether model retraining is necessary.

```{r echo=FALSE}
df_score = bind_rows(df_score, tibble(month='benchmark'
                                      , score = pmax(500, rnorm(1000, mean = 650, sd = 50))))
unique_months_score = unique(df_score$month)

ojs_define(score=df_score)
ojs_define(cohorts=unique_months_score)
```

```{ojs}
//| echo: false
//| panel: input
viewof select = Inputs.select(cohorts, {label: "Select one"})
```

```{ojs}
//| echo: false
filtered_data_score = transpose(score).filter(d => ['benchmark', select].includes(d.month))
```

:::: {layout="[50, 50]"}

::: {#first-column}
```{ojs}
Plot.plot({
  color: {
    legend: true
    , type: "categorical"
    , scheme: "viridis"},
  marks: [
    Plot.rectY(filtered_data_score, Plot.binX({y2: "count"}, {x: "score", fill:'month', mixBlendMode: "multiply", fillOpacity: 0.4})),
    Plot.ruleY([0])
  ]
})
```
:::

::: {#second-column}
```{ojs}
Plot.plot({
  marginLeft: 60,
  y: {grid: true},
  color: {legend: true,
         type: "categorical"
         , scheme: "viridis"}, 
  marks: [
        Plot.areaY(filtered_data_score.filter(d => d.month === "benchmark"), Plot.binX({y: "proportion"}, {x: "score", cumulative:1, fill:"month", fillOpacity: 0.4})),
    Plot.lineY(filtered_data_score.filter(d => d.month != "benchmark"), Plot.binX({y: "proportion"}, {x: "score", cumulative:1, stroke:"month"})),
    Plot.ruleY([0])
  ]
})
```
:::

::::

### Does the Default Rate Show Monotonicity with the Score?

The minimum requirement for a score is that the default rate should decrease as the score increases. This ensures that the score effectively ranks clients by their credit risk.

```{r data_simulation}

score <- rnorm(1000000, 600, 50) %>% round()

calculate_good_probability <- function(score){
  x <- log(2)/50*(score-300)
  p <- exp(x)/(1+exp(x))
  return(p)
}

behaviour <- score %>% map_int(~sample(c(0, 1), 1
                                       , prob=c(calculate_good_probability(.x), 1-calculate_good_probability(.x))))

simulated_data <- tibble(score=score, behaviour=behaviour) %>% 
  filter(score>=500, score<=800) %>%
  mutate(bin = cut_width(score, width=50)) 
```

```{r}
arrows <- tribble(
  ~x1, ~x2, ~y1, ~y2,
  4, 3, 3e5 + 5000, 3.5e5,
  6, 5, 1e5 - 5000, 0.2e5,
)
simulated_data %>% 
  group_by(bin) %>% 
  summarise(bad_rate = mean(behaviour), n = n()) %>%
  ggplot(aes(x=bin)) +
  geom_bar(aes(y=n), stat = 'identity', alpha=1, fill = "#fde725") +
  geom_line(aes(y=bad_rate*4000000, group=1), color = "#443983") +
  annotate("text", x = 4+0.3, y = 3e5, label = "# of clients") +
  annotate("text", x = 6+0.5, y = 1e5 + 4000, label = "ratio of bad clients") +
  geom_curve(
    data = arrows, aes(x = x1, xend = x2,
                       y = y1, yend = y2),
    arrow = arrow(length = unit(0.08, "inch")), 
    size = 0.5,
    color = "gray20", curvature = 0.3#
  ) +
  scale_y_continuous(
    name = "client #",
    sec.axis = sec_axis(~ . /4000000, name = "ratio of bad client")
  ) + xlab('') + theme_minimal()
```

### Are Performance Metrics Declining after Deployment?

Similar to the training process, it’s important to calculate performance metrics on the new data accumulated from the production system. If metrics such as KS or AUC are deteriorating, it’s time to reconsider whether the model should continue being used to assess new clients.

#### KS

```{r KS_data}
# Make two random #| samples
sample1<-simulated_data %>% filter(behaviour==1) %>% pull(score)
sample2<-simulated_data %>% filter(behaviour==0) %>% pull(score)

# group <- c(rep("sample1", length(sample1)), rep("sample2", length(sample2)))
# dat <- data.frame(KSD = c(sample1,sample2), group = group)
cdf1 <- ecdf(sample1) 
cdf2 <- ecdf(sample2) 

minMax <- seq(min(sample1, sample2), max(sample1, sample2), length.out=length(sample1)) 
x0 <- minMax[which( abs(cdf1(minMax) - cdf2(minMax)) == max(abs(cdf1(minMax) - cdf2(minMax))) )] 
y0 <- cdf1(x0) 
y1 <- cdf2(x0) 

KS = max(abs(cdf1(minMax) - cdf2(minMax)))

simulated_data <- simulated_data %>% 
  mutate(client_type=factor(behaviour
                            , levels = c(0, 1)
                            , labels = c('good', 'bad')))
```

```{r KS_plot}
ggplot(simulated_data, aes(x = score, group = client_type, colour = client_type, linetype=client_type))+
  stat_ecdf(size=1) +
  ylab("Cumulitive Distibution") +
  geom_segment(aes(x = x0[1], y = y0[1], xend = x0[1], yend = y1[1]),
               linetype = "dashed", color = "red") +
  geom_point(aes(x = x0[1] , y= y0[1]), color="red", size=1) +
  geom_point(aes(x = x0[1] , y= y1[1]), color="red", size=1) +
  ggtitle(paste0("K-S Test: ", round(KS, 3))) + 
  xlab('') + theme_minimal()
```


#### AUC

```{r}
#load necessary packages
library(ggplot2)
library(pROC)

#define object to plot
rocobj <- roc(simulated_data$behaviour, simulated_data$score)

auc <- round(auc(simulated_data$behaviour, simulated_data$score), 4)

ggroc(rocobj, colour = "#443983", size = 1) +
  ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')')) + 
  theme_minimal()
```

## The Similarity Between Credit Data and Demographics

I’ve found that analyzing credit data is similar to analyzing demographic data. With my experience in demographic research, where I’ve used survival models and multistate models, it occurred to me that some of the techniques used in demographic analysis could also be applied to credit data.

### Business Expansion or Contraction

As the economy slows in China, we are witnessing a decline in the amount of money being lent. For any given product or business, analyzing the loan tenure distribution of the current balance can provide insights into whether the business is expanding or contracting—similar to how demographers interpret population pyramids.

![Population Pyramid Example](https://user-images.githubusercontent.com/68678549/103846423-02cc4980-50d9-11eb-8c31-964d5cc1f7b8.png)

### Risk Increasing or Decreasing

In demographic analysis, tools used to analyze mortality rates—such as life tables, cohort analysis, and period analysis—offer parallels in credit analysis. For example, a defaulted loan can be likened to a deceased person, with the key difference being that a loan has some chance of being repaid in the future. I can already see how these demographic techniques have equivalents in credit analysis. This leads me to wonder: Can I apply [Lee-Carter Models](https://en.wikipedia.org/wiki/Lee%E2%80%93Carter_model) to decompose the cohort and period trends in default risk?

### Hazard Rate

In credit models, we typically begin by defining the “default” status through data analysis. A client is considered “bad” if they have more than 30 days of overdue payments within a 6-month period after the loan is issued. In demographic research, however, the focus is on analyzing the “hazard rate” to assess transitions between different states. With a solid toolbox of survival models (or time-to-event models, multistate models) at our disposal, I believe that by simply switching the data, we could uncover some interesting results in credit analysis as well.
