---
title: "How to Monitor a Credit Business"
author: "Qi Wang"
date: last-modified
categories: ["credit risk", "monitoring"]
format: 
  html:
    mermaid:
      theme: default
execute: 
  echo: false
  warning: false
  error: false
  cache: false
  freeze: auto
toc: true
toc-depth: 3
number-sections: true
---

## Data Generating Process

The first thing when starting analyzing some data from one specific domain, is to know the data generating process. That is why we need to have some domain knowledge or seek help from the subject matter experts. Lending and borrowing are very commaon activities in daily life. To better understand what kind of data we are going to deal with, I drew a diagram to show the simplified data generating process.

![Simplified Data Genrating Process](DGP.svg){width=80%}

During the application, applicants features like demographic characteristics and socioeconomic characteristics and other relevant data are used to evaluate their creditworthiness. Disqualified applicants will be rejecter. For those accepted applicants, a price (interest rate) and credit line amount will be assigned to them. After becoming a client with some credits, they can use the credit according to the agreement between the bank and the clients. But basically, we can observe two types of actions, borrowing and paying back.

So for the monitoring part, we mainly monitor the business data generated by our clients. For those rejected clients, we will never know their counter factual behaviour if they get the credit. They only appear in the data analysis of the application process. The rejection rates of the current application strategy. What are the distributions of the rejected reasons now. Are there any pattern change in the reject reasons? 


## Monitor the Application Process

An overview of the rejection data. The reject process always takes several steps. An applicant might go through several decision engines. In my example, I simulated the data so that it represents a process that the application first goes through the anti-fraud engine, then if passed, they will go through the strategy engine. It can reduce the need to fetch the downstream data for those rejected applicants, hence saving the cost to buy the data. (Yes, data is not free.)

```{r passrate}
library(tidyverse)
library(plotly)
library(lubridate)

# Generate a sequence of year months
start_date <- ym("2023-01")
end_date <- ym("2023-12")
months <- seq.Date(start_date, end_date, by = "1 month")

# Format the sequence as year-month
formatted_months <- format(months, "%Y-%m")

result <- as.factor(c("reject-antifraud", "reject-strategy", "pass"))

generate_probabilities <- function() {
    # Generate random probabilities for a, b, and c
    prob_a <- runif(1)
    prob_b <- runif(1)
    prob_c <- runif(1)

    # Normalize the probabilities to ensure they add up to 1
    total_prob <- prob_a + prob_b + prob_c
    prob_a <- prob_a / total_prob
    prob_b <- prob_b / total_prob
    prob_c <- prob_c / total_prob

    return(sort(c(prob_a, prob_b, prob_c)))
}

# Function to generate a dataframe for each item in the vector
generate_dataframe <- function(item) {
    data_frame <- data.frame(
        month = item,
        result = sample(result, size = sample(10000:50000, 1), replace = TRUE, prob = generate_probabilities())
    )
    return(data_frame)
}

fig <- formatted_months %>%
    map_df(generate_dataframe) %>%
    bind_rows()

fig <- as_tibble(fig)

fig <- fig %>%
    mutate(reject_reasons = map(result, ~ sample(letters[1:20],
        size = sample(1:7, 1),
        prob = c(log(2:11), log(15:6))
    )))

fig <- fig %>% mutate(reject_reasons = ifelse(result == "通过", list(), reject_reasons))
# fig <- ggplot2::diamonds

t_reject_reasons <- fig %>% filter(result != "通过")

fig <- plot_ly(
    x = fig$month,
    color = fig$result,
    type = "histogram", histfunc = "sum"
) %>%
    layout(barmode = "stack", barnorm = "percent")

fig
```

So when we see the pass rate fluctuate significantly, we may want to zoom in to see the reject reasons for each period.

```{r reject_reasons}
t_reject_reason_count <- t_reject_reasons %>%
    unnest(reject_reasons) %>%
    group_by(month, reject_reasons) %>%
    summarise(n = n())
unique_months <- unique(t_reject_reason_count$month)
max_n <- t_reject_reason_count$n %>% max()
ojs_define(reject_reason = t_reject_reason_count)
ojs_define(unique_months = unique_months)
ojs_define(max_n = max_n)
```

### Monitor the Reject Reasons

```{ojs}
//| echo: false
//| panel: input
viewof select_month = Inputs.select(unique_months, {label: "Select the Month"})
```


::: {.panel-tabset}

#### Visualization

```{ojs}
Plot.plot({
  y: {domain: [0, max_n], 
  label: "trigger times"},
  x: {label: "trigger reasons"},

marks: [
Plot.barY(filtered_data, {x: "reject_reasons", y: "n", fill: "reject_reasons", sort: {x: "y", limit:10, reverse: true}})]
})
```

#### Data
```{ojs}
Inputs.table(filtered_data)
```

:::

```{ojs}
//| echo: false
filtered_data = transpose(reject_reason).filter((d) => d.month === select_month)
```

### Model Score Distribution

Another way to check the quality of the incoming clients is to check the distribution of the model score or some important features. Basically, all scores that asess the clients' credit worthiness are just some way to reduce the dimensionality of the features we can get for that person and map them into a one-dimension scalar number. So we can compare two clients simply by ranking their scores. Assuming we have a model that is effective, we can be alarmed earlier whether there is a significant credit worthiness drift in our client base.


```{r violin_plot}
library(plotly)
library(tidyverse)
library(ggplot2)
library(showtext)
showtext_auto()

# simulate some client data to visualize
balance_age <- 0:19

generate_cohorts <- function(start = "2021-01", end = "2021-12") {
    # Generate a sequence of year months
    start_date <- ym(start)
    end_date <- ym(end)
    months <- seq.Date(start_date, end_date, by = "1 month")

    # Format the sequence as year-month
    cohorts <- format(months, "%Y-%m")
    return(cohorts)
}

cohorts <- generate_cohorts()

# simulate scores for each month
df_score <- cohorts %>%
    map(~ tibble(
        month = .x,
        score = pmax(500, rnorm(1000, mean = sample(600:700, 1), sd = 50))
    )) %>%
    bind_rows()
p_boxplot <- ggplot(data = df_score) +
    geom_boxplot(aes(x = month, y = score, fill = month)) +
    theme_minimal()

ggplotly(p_boxplot)
```

## Monitor Client Behaviour Data

To be continued, I will introduce the main metrics used to assess the health of the credit business, like vintage, rolling rate and so on.

### When to Use the Credit

We give out credit to clients based on their creditworthiness. But not every client is going to use them. We need to monitor the credit utilization rate to see if the business is healthy.

```{r}
data_credit_uti <- cohorts %>%
    map(~ tibble(
        cohort = .x,
        applied_clients = rnorm(1, 100000, 10000),
        utilize_prop = min(rnorm(1, 0.6, 0.1), 1),
        utilize_client = round(utilize_prop * applied_clients)
    )) %>%
    bind_rows()

fig <- plot_ly() %>%
    add_trace(
        data = data_credit_uti, x = ~cohort, y = ~applied_clients,
        type = "bar", name = "# Clients", hovertemplate = "Approval Month：%{x}<br># Clients: %{y}<extra></extra>"
    )

ay <- list(
    overlaying = "y",
    side = "right",
    title = "credit utilization rate"
)

fig <- fig %>% add_trace(
    data = data_credit_uti, x = ~cohort, y = ~utilize_prop,
    name = "credit utilization rate", yaxis = "y2", mode = "lines+markers",
    type = "scatter",
    hovertemplate = "Approval Month：%{x}<br>util. rate: %{y:.0%}<extra></extra>"
)

fig <- fig %>%
    layout(
        title = "",
        yaxis2 = ay,
        xaxis = list(title = ""),
        yaxis = list(title = "Approved Number of Clients")
    ) %>%
    layout(
        xaxis = list(
            zerolinecolor = "#ffff",
            zerolinewidth = 2,
            gridcolor = "ffff"
        ),
        yaxis = list(
            zerolinecolor = "#ffff",
            zerolinewidth = 2,
            gridcolor = "ffff"
        )
    )

fig
```

How long will a client start to use the credit after approval? We can use check the distribution to have a general idea. You can always refine it by split the data into more detailed groups, such as approval months.
```{r}
time_to_use <- rchisq(sample(10000:50000, 1), 40) %>% round()

plot_ly(x = time_to_use, type = "histogram")
```

### How is the Default Situation

The main risk of the credit business is the default. If we do not take time value into account, the final profit can be affected by the probability of default (PD) a lot.

$$profit = principal \cdot [(1-PD) \cdot i\% - c\% - PD \cdot (1 - r\%)]$$

#### Vintage

We need to monitor it closely to prevent any avoidable loss. One way to measure the default risk is the vintage analysis. It is a concept borrowed from enology. The loans issued in different periods or under different strategies can progress differently in regards to default rate. The overall shape are always increase generally then flatten out when the loans become mature until all the loans are settled.

```{r tanh}
gen_vintage_data <- function(cohort_name){
  age <- seq(0, 100)
  vintage <- tanh(age/10)*runif(1, 0.01, 0.07)

  df = data.frame(cohort = cohort_name, age = age, default_rate = vintage)
  return(df)
}

df <- purrr::map_df(sample(letters, 3), gen_vintage_data) %>% rbind()

vintage_plot <- ggplot(data=df) +
  geom_line(aes(x=age, y=default_rate, col=cohort)) + 
  theme_minimal()

ggplotly(vintage_plot)
```

#### Rolling Rate

The vintage fixes the cohort and shows the progressiong along time. The rolling rate measures how the accounts swtich between different states in a fixed period of time. For example, we can measure which proportion of accouns that have already got state M1 (overdue days between 1 and 29 days) will deteriorate to the next state M2 (overdue days between 30 days and 59 days) 30 days later. In observations, the longer a client has defaulted, the less probable he/she will repay the debt. So generally, you will see the rolling rates increase as the states worsen.

```{r migration_rate}
n <- length(cohorts)
df_mig <- tibble(cohort = cohorts
      , c_m1 = pmax(0, rnorm(n, 0.05, 0.02))
       , m1_m2 = pmax(0, rnorm(n, 0.3, 0.05))
       , m2_m3 = pmax(0, rnorm(n, 0.8, 0.1))
       , m3_m4 = pmax(0, rnorm(n, 0.9, 0.05))
       , m4_m5 = pmax(0, rnorm(n, 0.95, 0.05))
       , m5_m6 = pmax(0, rnorm(n, 0.99, 0.03))
       )

df_mig_long <- df_mig %>% pivot_longer(cols = -1, names_to = 'migrate_status', values_to = 'value') 
ojs_define(df_mig = df_mig_long)
```

```{ojs}
// this plot is ugly, refine it later
Plot.plot({
  color: {legend: true}, 
  y: {label: null},
  x: {label: null},
  marks: [
    Plot.cell(transpose(df_mig), {
      x: 'cohort',
      y: 'migrate_status',
      fill: 'value',
      tip: true 
    })
  ]
})
```

## Monitor the Effectiveness of the Model Scores

We have a lot of scores to measure clients' credit worthiness during the application and credit using processes, like application score or behaviour score. When we construct our models, we will evaluate the performance of our models by metrics like accuracy, ROC AUC, KS etc. After deployment, it is essential to monitor how well the scores generalize to unseen real-life clients. As we have seen above, our new clients need some time to interact with our business and show whether they are good clients or bad clients by their borrowing and paying back behaviours. 

### Score Stability

But first, we can monitor the distribution of the scores of new applicants to see if there is any significant drift of our client profiles. If it is drifting too much from the data that we train our model on, you should be alarmed and consider if it needs a retrain.

```{r echo=FALSE}
df_score = bind_rows(df_score, tibble(month='benchmark'
                                      , score = pmax(500, rnorm(1000, mean = 650, sd = 50))))
unique_months_score = unique(df_score$month)

ojs_define(score=df_score)
ojs_define(cohorts=unique_months_score)
```

```{ojs}
//| echo: false
//| panel: input
viewof select = Inputs.select(cohorts, {label: "Select one"})
```

```{ojs}
//| echo: false
filtered_data_score = transpose(score).filter(d => ['benchmark', select].includes(d.month))
```

:::: {layout="[50, 50]"}

::: {#first-column}
```{ojs}
Plot.plot({
  color: {legend: true, type: "ordinal"},
  marks: [
    Plot.rectY(filtered_data_score, Plot.binX({y2: "count"}, {x: "score", fill:'month', mixBlendMode: "multiply", fillOpacity: 0.4})),
    Plot.ruleY([0])
  ]
})
```
:::

::: {#second-column}
```{ojs}
Plot.plot({
  marginLeft: 60,
  y: {grid: true},
  color: {legend: true,
         type: "ordinal"}, 
  marks: [
        Plot.areaY(filtered_data_score.filter(d => d.month === "benchmark"), Plot.binX({y: "proportion"}, {x: "score", cumulative:1, fill:"month", fillOpacity: 0.4})),
    Plot.lineY(filtered_data_score.filter(d => d.month != "benchmark"), Plot.binX({y: "proportion"}, {x: "score", cumulative:1, stroke:"month"})),
    Plot.ruleY([0])
  ]
})
```
:::

::::

### Does the Default Rate Show Monotonicy with the Score?

The least requirement for a score is that the default rate should decrease as the score increase so it is effective to rank clients by their credit risk.

```{r data_simulation}

score <- rnorm(1000000, 600, 50) %>% round()

calculate_good_probability <- function(score){
  x <- log(2)/50*(score-300)
  p <- exp(x)/(1+exp(x))
  return(p)
}

behaviour <- score %>% map_int(~sample(c(0, 1), 1
                                       , prob=c(calculate_good_probability(.x), 1-calculate_good_probability(.x))))

simulated_data <- tibble(score=score, behaviour=behaviour) %>% 
  filter(score>=500, score<=800) %>%
  mutate(bin = cut_width(score, width=50)) 

simulated_data %>% 
  group_by(bin) %>% 
  summarise(bad_rate = mean(behaviour), n = n()) %>%
  ggplot(aes(x=bin)) +
  geom_bar(aes(y=n), stat = 'identity', alpha=0.5) +
  geom_line(aes(y=bad_rate*4000000, group=1))+
  scale_y_continuous(
    name = "client #",
    sec.axis = sec_axis(~ . /4000000, name = "ratio of bad client")
  ) + xlab('') + theme_minimal()
```

### Are Performance Metrics Declining after Deployment?

Just like what we do during our training process, we still need to calculate the metrics on the new data accummulated from production system. If the KS or AUC metrics are deteriorating, it's time to rethink if the model should still be used to assess the new clienteles.

#### KS

```{r KS_plot}
# Make two random #| samples
sample1<-simulated_data %>% filter(behaviour==1) %>% pull(score)
sample2<-simulated_data %>% filter(behaviour==0) %>% pull(score)

# group <- c(rep("sample1", length(sample1)), rep("sample2", length(sample2)))
# dat <- data.frame(KSD = c(sample1,sample2), group = group)
cdf1 <- ecdf(sample1) 
cdf2 <- ecdf(sample2) 

minMax <- seq(min(sample1, sample2), max(sample1, sample2), length.out=length(sample1)) 
x0 <- minMax[which( abs(cdf1(minMax) - cdf2(minMax)) == max(abs(cdf1(minMax) - cdf2(minMax))) )] 
y0 <- cdf1(x0) 
y1 <- cdf2(x0) 

KS = max(abs(cdf1(minMax) - cdf2(minMax)))

simulated_data <- simulated_data %>% 
  mutate(client_type=factor(behaviour
                            , levels = c(0, 1)
                            , labels = c('good', 'bad')))

ggplot(simulated_data, aes(x = score, group = client_type, colour = client_type, linetype=client_type))+
  stat_ecdf(size=1) +
  ylab("Cumulitive Distibution") +
  geom_segment(aes(x = x0[1], y = y0[1], xend = x0[1], yend = y1[1]),
               linetype = "dashed", color = "red") +
  geom_point(aes(x = x0[1] , y= y0[1]), color="red", size=1) +
  geom_point(aes(x = x0[1] , y= y1[1]), color="red", size=1) +
  ggtitle(paste0("K-S Test: ", round(KS, 3))) + xlab('')


```


#### AUC

```{r}
#load necessary packages
library(ggplot2)
library(pROC)

#define object to plot
rocobj <- roc(simulated_data$behaviour, simulated_data$score)

auc <- round(auc(simulated_data$behaviour, simulated_data$score), 4)

ggroc(rocobj, colour = 'steelblue', size = 1) +
  ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')')) + 
  theme_minimal()
```

## the Similarity between Credit Data and Demography

I found the process of anlysing the credit data is similar to the analysis of the demographic data. I have expeience in demographic research and used survival models, multistate models in my research. It occurs to me that some of the techniques used in demographic analysis may be applicable to the credit data.

### Business Expanding or Contracting

Nowadays as the economy is decelerating in China, we see the amount of money lent is decreasing too. For one single product or business, if we analyze the loan tenure distribution of current balance, you will see if the business is prospering or shrinking.

![Population Pyramid Example](https://user-images.githubusercontent.com/68678549/103846423-02cc4980-50d9-11eb-8c31-964d5cc1f7b8.png)

### Risk Increasing or Decreasing

Other tools to analyze mortality rates (a defaulted loan is like a dying person, the only difference is the loan has some chance to get repayed someday in the futrue) like lifetables, cohort analysis and period analysis, I can already see some of their equivalents in credit analysis. Can I use [Lee-Carter Models](https://en.wikipedia.org/wiki/Lee%E2%80%93Carter_model) to decompose the cohort and period trends of default risks?

### Hazard Rate

In credit models, we always first define the status `default` by analysing the data first. Then we would define a client as a bad if they have a maximum overdue days greater than 30 days in a 6-month period after the loan is issued. But in demographic research, we always analyze the `hazard rate` to transit to other state. We already have a toolbox of suvival models (or time-of-event models, multistate models) under our belt, just switch the data and I bebieve there will be some interesting results.
